# ğŸ”¥ News
- *2024.09*: &nbsp;ğŸºğŸºğŸº I am honored to be recognized as an **Outstanding Reviewer** for CVPR 2025. Acknowledgement to CVPR!
- *2025.03*: &nbsp;ğŸºğŸºğŸº Our team, "ä»Šå¤©ä½ ç§‘ç ”äº†å—", win the **second place** in the finals of the 2nd Open Atom & HUAWEI Competition - [Innovation Contest for Training Online Monitoring Tools supported by Colossal AI](https://competition.atomgit.com/competitionInfo?id=9c368c336bcb14fa657f690a94519649). Congratulations to all team members!
- *2025.03*: &nbsp;ğŸ‘‘ğŸ‘‘ğŸ‘‘ I am honored to receive the **Best Oral Presentation Award** at [**ICIAI 2025**](https://www.iciai.org/html/2025.html). My sincere gratitude to ICIAI for this recognition!
- *2025.02*: &nbsp;ğŸ‰ğŸ‰ğŸ‰ [Distinguish Then Exploit](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Distinguish_Then_Exploit_Source-free_Open_Set_Domain_Adaptation_via_Weight_CVPR_2025_paper.html) is accepted by **CVPR 2025**!
- *2025.01*: &nbsp;ğŸ‰ğŸ‰ğŸ‰ [EHM](https://www.sciencedirect.com/science/article/abs/pii/S089360802500067X) is accepted by **Neural Networks 2025**!
- *2024.12*: &nbsp;ğŸ‰ğŸ‰ğŸ‰ [LLM4GEN](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=NB9Mn5MAAAAJ&sortby=pubdate&citation_for_view=NB9Mn5MAAAAJ:ufrVoPGSRksC) is accepted by **AAAI 2025**!
- *2024.10*: &nbsp;ğŸ‘‘ğŸ‘‘ğŸ‘‘ I am honored to be awarded the <span style="color: red;">**NeurIPS 2024 Scholar Award**</span>. My sincere thanks to NeurIPS for this recognition!
- *2024.09*: &nbsp;ğŸš€ğŸš€ğŸš€ [TopoFR](https://proceedings.neurips.cc/paper_files/paper/2024/hash/419b6c974712adb884bfbbeea8e94d1b-Abstract-Conference.html) and [TFGDA](https://proceedings.neurips.cc/paper_files/paper/2024/hash/59e73ff865b56cba6ab7f6b2cce1425d-Abstract-Conference.html) are accepted by **NeurIPS 2024**! Code and models are publicly available [here](https://github.com/DanJun6737/TopoFR)!
- *2024.09*: &nbsp;ğŸ‘‘ğŸ‘‘ğŸ‘‘ I am honored to receive the <span style="color: red;">**MM 24 Student Travel Grant Award**</span>. My heartfelt thanks to MM for this recognition!
- *2024.07*: &nbsp;ğŸ‰ğŸ‰ğŸ‰ [HOGDA](https://dl.acm.org/doi/abs/10.1145/3664647.3680765) is accepted by **ACM MM 2024**!
- *2024.05*: &nbsp;ğŸš€ğŸš€ğŸš€ TransFace is integrated in [FaceChain](https://github.com/modelscope/facechain) as a **key identity-preserved module** to assist Stable Diffusion in generating human portraits with fine-grained facial details and diverse styles. In the newest FaceChain-FACT version, with only 1 photo and 10 seconds, you can generate personal portraits in different settings (multiple styles now supported!).
- *2024.05*: &nbsp;ğŸ‰ğŸ‰ğŸ‰ [PRCL](https://link.springer.com/article/10.1007/s11263-024-02016-8) is accepted by **IJCV 2024**!
- *2023.10*: &nbsp;ğŸ‰ğŸ‰ğŸ‰ [TransFace](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=NB9Mn5MAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=NB9Mn5MAAAAJ:2osOgNQ5qMEC) is accepted by **ICCV 2023**! [Code](https://github.com/DanJun6737/TransFace) and [models](https://www.modelscope.cn/models/iic/cv_vit_face-recognition) are publicly available!







