# üìù Publications

A full publication list is available on my [google scholar](https://scholar.google.com.hk/citations?user=NB9Mn5MAAAAJ&hl=zh-CN) page.


<!-- Paper 1 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Open-Source Project</div><img src='images/FaceChain-FACT.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**Open-Source Project**] [FaceChain: A Playground for Human-centric Artificial Intelligence Generated Content](https://github.com/modelscope/facechain) \\
[![GitHub Stars](https://img.shields.io/github/stars/modelscope/facechain?style=social)](https://github.com/modelscope/facechain)
[![GitHub Forks](https://img.shields.io/github/forks/modelscope/facechain?style=social)](https://github.com/modelscope/facechain)
<a href='https://facechain-fact.github.io/'><img src='https://img.shields.io/badge/Project-Page-Green'></a>  [![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/DHqEl0qwi-M?si=y6VpInXdhIX0HpbI) \\
[[ModelScope Studio]](https://modelscope.cn/studios/CVstudio/FaceChain-FACT)
[[Alibaba Cloud‚Äå API]](https://help.aliyun.com/zh/model-studio/facechain-quick-start)
[[HuggingFace Space]](https://huggingface.co/spaces/modelscope/FaceChain-FACT)


- FaceChain is a novel framework for generating identity-preserved human portraits.
- FaceChain has both high controllability and authenticity in portrait generation, including text-to-image and inpainting based pipelines, and is seamlessly compatible with ControlNet and LoRAs.



</div>
</div>


<!-- Paper 2 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/TransFace.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**ICCV 2023**] [TransFace: Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective](https://openaccess.thecvf.com/content/ICCV2023/html/Dan_TransFace_Calibrating_Transformer_Training_for_Face_Recognition_from_a_Data-Centric_ICCV_2023_paper.html) \\
**Jun Dan**, Yang Liu, Haoyu Xie, Jiankang Deng, Haoran Xie, Xuansong Xie, Baigui Sun \\
[![GitHub Stars](https://img.shields.io/github/stars/DanJun6737/TransFace?style=social)](https://github.com/DanJun6737/TransFace)
[![GitHub Forks](https://img.shields.io/github/forks/DanJun6737/TransFace?style=social)](https://github.com/DanJun6737/TransFace)
[[**ModelScope**]](https://www.modelscope.cn/models/iic/cv_vit_face-recognition)
[[Code in FaceChain Rep.]](https://github.com/modelscope/facechain/tree/main/face_module/TransFace)
[[ÈòøÈáå‰∫ë]](https://developer.aliyun.com/article/1319924)
[[CSDN]](https://blog.csdn.net/sunbaigui/article/details/136556006)

- TransFace is a cutting-edge facial representation extractor in the AIGC era, designed to capture fine-grained facial features at the patch-level.
- TransFace is integrated in [FaceChain](https://github.com/modelscope/facechain) as a **key identity-preserved module** to assist Stable Diffusion in generating human portraits with fine-grained facial details and diverse styles.
- **Industry Impact:** TransFace model has reached over **15K+** downloads on the [**ModelScope**](https://www.modelscope.cn/models/iic/cv_vit_face-recognition) platform, and has been applied in various facial AIGC projects, such as [Alibaba Tongyi Wanxiang (ÈÄö‰πâ‰∏áË±°ÂÜôÁúüÈ¶Ü)](https://tongyi.aliyun.com/wanxiang/), [FaceChain](https://github.com/modelscope/facechain), Fliggy (È£ûÁå™Êï∞Â≠óÊóÖÊãç), etc.



</div>
</div>


<!-- Paper 3 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024 </div><img src='images/TopoFR.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**NeurIPS 2024**] [TopoFR: A Closer Look at Topology Alignment on Face Recognition](https://proceedings.neurips.cc/paper_files/paper/2024/hash/419b6c974712adb884bfbbeea8e94d1b-Abstract-Conference.html) \\
**Jun Dan**, Yang Liu, Jiankang Deng, Haoyu Xie, Siyuan Li, Baigui Sun, Shan Luo
[![GitHub Stars](https://img.shields.io/github/stars/modelscope/facechain?style=social)](https://github.com/modelscope/facechain)
[![GitHub Forks](https://img.shields.io/github/forks/modelscope/facechain?style=social)](https://github.com/modelscope/facechain)
<a href='https://huggingface.co/spaces/developer0hye/TopoFR-Face-Recognition'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-blue'></a>
[[Êú∫Âô®‰πãÂøÉ]](https://www.jiqizhixin.com/articles/2024-10-17-6) 
[[CVer]](https://mp.weixin.qq.com/s/3NegnpJUGPfI_dOfkp_4LQ) 
[[CSDN]](https://blog.csdn.net/sunbaigui/article/details/143230746?spm=1001.2014.3001.5502)

- TopoFR is the first attempt to leverage the powerful and substantial structure information hidden in large-scale face dataset to improve the generalization performance of face recognition models.
- TopoFR achieves SOTA performance on various face benchmarks.


</div>


<!-- Paper 4 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TPAMI 2025 </div><img src='images/TransFace_pp.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**TPAMI 2025**] [TransFace++: Rethinking the Face Recognition Paradigm with a Focus on Accuracy, Efficiency, and Security](https://ieeexplore.ieee.org/abstract/document/11184862) \\
**Jun Dan**, Yang Liu, Baigui Sun, Jiankang Deng, Shan Luo
[![GitHub Stars](https://img.shields.io/github/stars/DanJun6737/TransFace_pp?style=social)](https://github.com/DanJun6737/TransFace_pp)
[![GitHub Forks](https://img.shields.io/github/forks/DanJun6737/TransFace_pp?style=social)](https://github.com/DanJun6737/TransFace_pp)

- TransFace++ is the first cutting-edge FR backbone that operates directly on images bytes, which opens up a viable path for future research on FR
privacy-preserving systems.
- Unlike conventional FR models that perform inference on RGB tensors, TransFace++ directly makes predictions on image bytes, bypassing the complex image decoding steps, and greatly boosting the real-time capability of FR systems.


</div>
</div>


<!-- Paper 5 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2024 </div><img src='images/TFGDA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**NeurIPS 2024**] [TFGDA: Exploring Topology and Feature Alignment in Semi-supervised Graph Domain Adaptation through Robust Clustering](https://proceedings.neurips.cc/paper_files/paper/2024/hash/59e73ff865b56cba6ab7f6b2cce1425d-Abstract-Conference.html) \\
**Jun Dan**, Weiming Liu, Chunfeng Xie, Hua Yu, Shunjie Dong, Yanchao Tan

- TFGDA is an advanced graph transfer learning framework that leverages the intrinsic topological structure information embedded in graphs to improve model generilization performance across domains.
- TFGDA showcases superior performance on multiple transfer learning benchmarks.


</div>
</div>


<!-- Paper 6 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2024 </div><img src='images/HOGDA.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**ACM MM 2024**] [HOGDA: Boosting Semi-supervised Graph Domain Adaptation via High-Order Structure-Guided Adaptive Feature Alignment](https://dl.acm.org/doi/abs/10.1145/3664647.3680765) \\
**Jun Dan**, Weiming Liu, Mushui Liu, Chunfeng Xie, Shunjie Dong, Guofang Ma, Yanchao Tan, Jiazheng Xing

- HOGDA is a novel graph transfer learning framework that incorporates a high-order structure information mixing module, effectively capturing abundant structure information in graphs and greatly enhancing the feature extractor's adaptability across different domains.
- HOGDA demonstrates remarkable transfer performance on various benchmarks.


</div>
</div>


<!-- Paper 7 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025 </div><img src='images/DTE.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[**CVPR 2025**] [Distinguish Then Exploit: Source-free Open Set Domain Adaptation via Weight Barcode Estimation and Sparse Label Assignment](https://openaccess.thecvf.com/content/CVPR2025/html/Liu_Distinguish_Then_Exploit_Source-free_Open_Set_Domain_Adaptation_via_Weight_CVPR_2025_paper.html) \\
Weiming Liu\*, **Jun Dan**\*, Fan Wang, Xinting Liao, Junhao Dong, Hua Yu, Shunjie Dong, Lianyong Qi (*: equal contribution.)


- DTE is a novel framework designed for source-free open set domain adaptation problem. By integrating weight barcode estimation with sparse label assignment, DTE enables efficient and robust knowledge transfer across domains.
- DTE outperforms SOTA models on tackling the source-free open set domain adaptation problem.


</div>
</div>


